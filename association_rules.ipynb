{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1afb416",
   "metadata": {},
   "source": [
    "## Association Rule Mining with Simulated Data\n",
    "\n",
    "Objective: Simulate basic transactional data and use association rules to uncover shopping patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6f6f6",
   "metadata": {},
   "source": [
    "### 1. Simulate Transaction Data\n",
    "\n",
    "- Create at least **10 fake transactions** in Python.\n",
    "\n",
    "- Each transaction should have **2-5 items** selected from a pool of **atleast 8 unique items** (e.g., Bread, Milk, Eggs, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db749fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b56f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Transactions:\n",
      "Transaction 1: ['ladoo', 'shrikhand']\n",
      "Transaction 2: ['ladoo', 'shrikhand', 'chevdo', 'barfi', 'khoya']\n",
      "Transaction 3: ['rasmalai', 'chevdo', 'chakri', 'bhusu']\n",
      "Transaction 4: ['bhusu', 'rasmalai', 'sev', 'chakri']\n",
      "Transaction 5: ['barfi', 'shrikhand']\n",
      "Transaction 6: ['shrikhand', 'chevdo', 'rasmalai', 'gathiya', 'farsipuri']\n",
      "Transaction 7: ['shrikhand', 'chakri']\n",
      "Transaction 8: ['chevdo', 'ladoo', 'barfi']\n",
      "Transaction 9: ['ladoo', 'gathiya', 'chevdo', 'khoya', 'chakri']\n",
      "Transaction 10: ['sev', 'farsipuri', 'bhusu', 'rasmalai', 'chevdo']\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "random.seed(123)\n",
    "\n",
    "# Creating a product pool \n",
    "products = ['chevdo', 'shrikhand', 'chakri', 'sev', 'ladoo', \n",
    "           'rasmalai', 'barfi', 'gathiya', 'bhusu', 'farsipuri', 'khoya']\n",
    "\n",
    "# Generating 10 random transactions\n",
    "dataset = []\n",
    "for x in range(10):\n",
    "    # Randomly choose 2-5 items per transaction\n",
    "    transaction = random.sample(products, k=random.randint(2,5))\n",
    "    dataset.append(transaction)\n",
    "\n",
    "# Displaying the simulated data\n",
    "print(\"Generated Transactions:\")\n",
    "for i, t in enumerate(dataset, 1):\n",
    "    print(f\"Transaction {i}: {t}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a0b6d",
   "metadata": {},
   "source": [
    "### 2. Analyze with Apriori\n",
    "\n",
    "- Convert the data into a **one-hot encoded format** using pandas.\n",
    "\n",
    "- Use the Apriori algorithm (mlxtend) to find frequent itemsets.\n",
    "\n",
    "- Set minimum support to **0.3** (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7deab1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "    support            itemsets\n",
      "0      0.3             (barfi)\n",
      "1      0.3             (bhusu)\n",
      "2      0.4            (chakri)\n",
      "3      0.6            (chevdo)\n",
      "4      0.4             (ladoo)\n",
      "5      0.4          (rasmalai)\n",
      "6      0.5         (shrikhand)\n",
      "7      0.3   (bhusu, rasmalai)\n",
      "8      0.3     (ladoo, chevdo)\n",
      "9      0.3  (chevdo, rasmalai)\n"
     ]
    }
   ],
   "source": [
    "# Converting the data to one-hot encoded DataFrame\n",
    "all_items = sorted(set(item for transaction in dataset for item in transaction))\n",
    "encoded_data = []\n",
    "\n",
    "for transaction in dataset:\n",
    "    encoded_data.append({item: (item in transaction) for item in all_items})\n",
    "\n",
    "df = pd.DataFrame(encoded_data)\n",
    "\n",
    "# using the Apriori algorithm to find frequent itemsets with a minimum support of 0.3\n",
    "frequent_itemsets = apriori(df, min_support=0.3, use_colnames=True)\n",
    "\n",
    "''' \n",
    "frequent itemsets: it is a group of items that appear together in transactions more often than a specified threshold (in this case, 30% of the transactions).\n",
    "'min_support=0.3': this means we are looking for itemsets that appear in at least 30% of the transactions.\n",
    "\n",
    "'''\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Frequent Itemsets:\\n\", frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a908a31",
   "metadata": {},
   "source": [
    "### 3. Generate Rules \n",
    "\n",
    "- Generate association rules with:\n",
    "    \n",
    "    - Metric: confidence\n",
    "\n",
    "    - Minimum threshold: 0.7\n",
    "    \n",
    "- Show **at least 2 rules** and briefly explain **what one rule means** in everyday language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d4eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "   antecedents consequents  support  confidence  lift\n",
      "0     (bhusu)  (rasmalai)      0.3        1.00  2.50\n",
      "1  (rasmalai)     (bhusu)      0.3        0.75  2.50\n",
      "2     (ladoo)    (chevdo)      0.3        0.75  1.25\n",
      "3  (rasmalai)    (chevdo)      0.3        0.75  1.25\n"
     ]
    }
   ],
   "source": [
    "# Generate association rules with a minimum confidence threshold of 0.7\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.7)\n",
    "\n",
    "# Displaying the results\n",
    "print(\"\\nAssociation Rules:\\n\", rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "'''\n",
    "- 'antecedents': the items that lead to the rule.\n",
    "- 'consequents': the items that are likely to be bought as a result.\n",
    "- 'support': the proportion of transactions that contain the itemset.\n",
    "- 'confidence': the likelihood that the consequent is bought when the antecedent is bought.\n",
    "- 'lift': a measure of how much more likely the consequent is bought when the antecedent is bought compared to when it is not.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958115a7",
   "metadata": {},
   "source": [
    "### Briefly describing atleast 2 rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69aaa15",
   "metadata": {},
   "source": [
    "#### Rule 1:\n",
    "\n",
    "antecedents: (bhusu)\n",
    "\n",
    "consequents: (rasmalai)\n",
    "\n",
    "support: 0.3\n",
    "\n",
    "confidence: 1.00\n",
    "\n",
    "lift: 2.50\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- antecedents (bhusu): this means that the rule is based on the purchase of 'bhusu'.\n",
    "\n",
    "- consequents (rasmalai): this shows that when a customer buys 'bhusu', they are also likely to buy 'rasmalai'.\n",
    "\n",
    "- support 0.3: This means that 30% of all transactions in the dataset include both 'bhusu' and 'rasmalai'.\n",
    "\n",
    "- confidence 1.00: This value indicates that whenever 'bhusu' is bought, 'rasmalai' is purchased 100% of the time. Simply put, every time someone buys 'bhusu' they also buy 'rasmalai'\n",
    "\n",
    "- lift 2.50: This value suggests that buying 'bhusu' increases the likelihood of buying 'rasmalai' by 125% compared to if there were bought independently.\n",
    "\n",
    "**Meaning:**\n",
    "\n",
    "If a customer buys bhusu, we are very confident that they will also buy rasmalai. This may suggest that they like spicy-sweet food.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c6035",
   "metadata": {},
   "source": [
    "#### Rule 2:\n",
    "\n",
    "antecedents: (ladoo)\n",
    "\n",
    "consequents: (chevdo)\n",
    "\n",
    "support: 0.3\n",
    "\n",
    "confidence: 0.75\n",
    "\n",
    "lift: 1.25\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- antecedents (ladoo): this means that the rule is based on the purchase of 'ladoo'.\n",
    "\n",
    "- consequents (chevdo): this shows that when a customer buys 'ladoo', they are also likely to buy 'chevdo'.\n",
    "\n",
    "- support 0.3: This means that 30% of all transactions in the dataset include both 'ladoo' and 'chevdo'.\n",
    "\n",
    "- confidence 0.75: This value indicates that whenever 'ladoo' is bought, 'chevdo' is purchased 75% of the time. Simply put, every time someone buys 'ladoo' they also buy 'chevdo'.\n",
    "\n",
    "- lift 1.25: This value suggests that buying 'ladoo' increases the likelihood of buying 'chevdo' by 25% compared to if there were bought independently.\n",
    "\n",
    "**Meaning:**\n",
    "\n",
    "If a customer buys ladoo, we are very confident that they will also buy chevdo. This may suggest that they like sweet-spicy food."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
